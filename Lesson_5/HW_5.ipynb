{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для нашего пайплайна (Case1) поэкспериментировать с разными моделями: 1 - бустинг, 2 - логистическая регрессия (не забудьте здесь добавить в cont_transformer стандартизацию - нормирование вещественных признаков)\n",
    "2. Отобрать лучшую модель по метрикам (кстати, какая по вашему мнению здесь наиболее подходящая DS-метрика)\n",
    "3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты.\n",
    "4. (опционально) Провести подбор гиперпараметров лучшей модели по итогам 2-3\n",
    "5. (опционально) Еще раз провести оценку экономической эффективности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"churn_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#соберем наш простой pipeline, но нам понадобится написать класс для выбора нужного поля\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим списки признаков\n",
    "categorical_columns = ['Geography', 'Gender', 'Tenure', 'HasCrCard', 'IsActiveMember']\n",
    "continuous_columns = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "\n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', FeatureSelector(column=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#объединим всё в единый пайплайн\n",
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "classifier_lgbm = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LGBMClassifier(max_depth=5, random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('Geography',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))],\n",
       "                                                          verbos...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='split',\n",
       "                                learning_rate=0.1, max_depth=5,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_leaves=31, objective=None, random_state=42,\n",
       "                                reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                subsample=1.0, subsample_for_bin=200000,\n",
       "                                subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "classifier_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_lgbm = classifier_lgbm.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_tresholds_lgbm= 0.309, f-score_lgbm= 0.637, precision_lgbm= 0.584, recall_lgbm= 0.701\n"
     ]
    }
   ],
   "source": [
    "precision_lgbm, recall_lgbm, thresholds_lgbm = precision_recall_curve(y_test, preds_lgbm)\n",
    "f_score_lgbm = (2 * precision_lgbm * recall_lgbm) / (precision_lgbm + recall_lgbm)\n",
    "ix_lgbm = np.argmax(f_score_lgbm)\n",
    "print('best_tresholds_lgbm= %.3f, f-score_lgbm= %.3f, precision_lgbm= %.3f, recall_lgbm= %.3f' % (thresholds_lgbm[ix_lgbm],\n",
    "                                                                                                 f_score_lgbm[ix_lgbm],\n",
    "                                                                                                precision_lgbm[ix_lgbm],\n",
    "                                                                                                recall_lgbm[ix_lgbm])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1737,  254],\n",
       "       [ 153,  356]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_lgbm = confusion_matrix(y_test, preds_lgbm>thresholds_lgbm[ix_lgbm])\n",
    "cnf_matrix_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('Geography',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))],\n",
       "                                                          verbos...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "classifier_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получим вероятности\n",
    "preds_rf = classifier_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_tresholds_rf= 0.500, f-score_rf= 0.607, precision_rf= 0.667, recall_rf= 0.556\n"
     ]
    }
   ],
   "source": [
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, preds_rf)\n",
    "f_score_rf = (2 * precision_rf * recall_rf) / (precision_rf + recall_rf)\n",
    "ix_rf = np.argmax(f_score_rf)\n",
    "print('best_tresholds_rf= %.3f, f-score_rf= %.3f, precision_rf= %.3f, recall_rf= %.3f' % (thresholds_rf[ix_rf],\n",
    "                                                                                                 f_score_rf[ix_rf],\n",
    "                                                                                                precision_rf[ix_rf],\n",
    "                                                                                                recall_rf[ix_rf])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1912,   79],\n",
       "       [ 277,  232]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_rf = confusion_matrix(y_test, preds_rf>thresholds_rf[ix_rf])\n",
    "cnf_matrix_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_log_loss = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('Geography',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))],\n",
       "                                                          verbos...\n",
       "                                                                                 with_mean=True,\n",
       "                                                                                 with_std=True))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_log_loss.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log_loss = classifier_log_loss.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_tresholds_log_loss= 0.290, f-score_log_loss= 0.510, precision_log_loss= 0.462, recall_log_loss= 0.568\n"
     ]
    }
   ],
   "source": [
    "precision_log_loss, recall_log_loss, thresholds_log_loss = precision_recall_curve(y_test, preds_log_loss)\n",
    "f_score_log_loss = (2 * precision_log_loss * recall_log_loss) / (precision_log_loss + recall_log_loss)\n",
    "ix_log_loss = np.argmax(f_score_log_loss)\n",
    "print('best_tresholds_log_loss= %.3f, f-score_log_loss= %.3f, precision_log_loss= %.3f, recall_log_loss= %.3f' % (thresholds_log_loss[ix_log_loss],\n",
    "                                                                                                 f_score_log_loss[ix_log_loss],\n",
    "                                                                                                precision_log_loss[ix_log_loss],\n",
    "                                                                                                recall_log_loss[ix_log_loss])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1655,  336],\n",
       "       [ 221,  288]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_log_loss = confusion_matrix(y_test, preds_log_loss>thresholds_log_loss[ix_log_loss])\n",
    "cnf_matrix_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'f_score': [f_score_lgbm[ix_lgbm], f_score_rf[ix_rf], f_score_log_loss[ix_log_loss]],\n",
    "                 'precision': [precision_lgbm[ix_lgbm], precision_rf[ix_rf], precision_log_loss[ix_log_loss]],\n",
    "                  'recall': [recall_lgbm[ix_lgbm], recall_rf[ix_rf], recall_log_loss[ix_log_loss]]}\n",
    "                 \n",
    "                 \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ['LGBM', 'RandomForest', 'LogLoss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogLoss</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_score  precision  recall\n",
       "LGBM            0.638      0.584   0.701\n",
       "RandomForest    0.607      0.667   0.556\n",
       "LogLoss         0.510      0.462   0.568"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод: здесь нужно максимизировать recall, поэтому наилучшая модель- LGBM.\n",
    "# Но получается, что нам нужно обращать внимание на FP. Если таких будет много,\n",
    "# то мы впустую потратим деньги на то, чтобы они остались, хотя они и так останутся. Нужно минимизировать FP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1737,  254],\n",
       "       [ 153,  356]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_test, preds_rf>thresholds_lgbm[ix_lgbm]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses = TP + FN\n",
    "expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = 2 * TP\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rev = income - expenses\n",
    "Rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заработали 129 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (опционально) Провести подбор гиперпараметров лучшей модели по итогам 2-3\n",
    "5. (опционально) Еще раз провести оценку экономической эффективности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'classifier__max_depth':[20, 30, 50],\n",
    "        'classifier__num_leaves':[10, 20, 30],\n",
    "        'classifier__n_estimators': [100, 200]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 20,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'classifier__num_leaves': 30}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(classifier_lgbm,\n",
    "                    param_grid=params,\n",
    "                    cv=5,\n",
    "                    scoring='recall',\n",
    "                    refit=False)\n",
    "\n",
    "search = grid.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучим модель с новыми параметрами\n",
    "\n",
    "classifier_lgbm_search = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LGBMClassifier(max_depth=20, n_estimators=100, num_leaves=30, random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('Geography',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))],\n",
       "                                                          verbos...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='split',\n",
       "                                learning_rate=0.1, max_depth=20,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_leaves=30, objective=None, random_state=42,\n",
       "                                reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                subsample=1.0, subsample_for_bin=200000,\n",
       "                                subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lgbm_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lgbm_search = classifier_lgbm_search.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_tresholds_lgbm_search= 0.376, f-score_lgbm_search= 0.646, precision_lgbm_search= 0.640, recall_lgbm_search= 0.652\n"
     ]
    }
   ],
   "source": [
    "precision_lgbm_search, recall_lgbm_search, thresholds_lgbm_search = precision_recall_curve(y_test, preds_lgbm_search)\n",
    "b=1\n",
    "fb_score_lgbm_search = (1+b**2) * (precision_lgbm_search * recall_lgbm_search) / (b**2 * precision_lgbm_search + recall_lgbm_search)\n",
    "ix_lgbm_search = np.argmax(fb_score_lgbm_search)\n",
    "print('best_tresholds_lgbm_search= %.3f, f-score_lgbm_search= %.3f, precision_lgbm_search= %.3f, recall_lgbm_search= %.3f' % (thresholds_lgbm_search[ix_lgbm_search],\n",
    "                                                                                                 fb_score_lgbm_search[ix_lgbm_search],\n",
    "                                                                                                precision_lgbm_search[ix_lgbm_search],\n",
    "                                                                                                recall_lgbm_search[ix_lgbm_search])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804 187 178 331\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_test, preds_lgbm_search>thresholds_lgbm_search[ix_lgbm_search]).ravel()\n",
    "print(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses = TP + FN\n",
    "expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = 2 * TP\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rev = income - expenses\n",
    "Rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заработали 153 $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
